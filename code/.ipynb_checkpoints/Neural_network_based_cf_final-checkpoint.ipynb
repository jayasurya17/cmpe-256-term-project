{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XFB7DQcLk4uA",
    "outputId": "fbe32a19-6e87-45c6-c8fc-b06571e90da9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting surprise\n",
      "  Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
      "Requirement already satisfied: scikit-surprise in c:\\users\\checkout\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from surprise) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\checkout\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-surprise->surprise) (1.5.2)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\checkout\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-surprise->surprise) (1.15.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\checkout\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-surprise->surprise) (0.17.0)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.0.1; however, version 21.1 is available."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy>=1.11.2 in c:\\users\\checkout\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-surprise->surprise) (1.19.2)\n",
      "Installing collected packages: surprise\n",
      "Successfully installed surprise-0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "You should consider upgrading via the 'c:\\users\\checkout\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "acaQURRCk9wT"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib.pyplot import figure\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import os\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import sparse\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "-3rF9T0pmE8r",
    "outputId": "ce6ae1e5-2982-4818-d8fe-9e7de7d43f81"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>rating</th>\n",
       "      <th>rented for</th>\n",
       "      <th>review_text</th>\n",
       "      <th>body type</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>category</th>\n",
       "      <th>height</th>\n",
       "      <th>size</th>\n",
       "      <th>age</th>\n",
       "      <th>bust_size</th>\n",
       "      <th>bust_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fit</td>\n",
       "      <td>420272</td>\n",
       "      <td>2260466</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>vacation</td>\n",
       "      <td>An adorable romper! Belt and zipper were a lit...</td>\n",
       "      <td>hourglass</td>\n",
       "      <td>So many compliments!</td>\n",
       "      <td>romper</td>\n",
       "      <td>68.0</td>\n",
       "      <td>M</td>\n",
       "      <td>28.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fit</td>\n",
       "      <td>273551</td>\n",
       "      <td>153475</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>other</td>\n",
       "      <td>I rented this dress for a photo shoot. The the...</td>\n",
       "      <td>straight &amp; narrow</td>\n",
       "      <td>I felt so glamourous!!!</td>\n",
       "      <td>gown</td>\n",
       "      <td>66.0</td>\n",
       "      <td>M</td>\n",
       "      <td>36.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fit</td>\n",
       "      <td>360448</td>\n",
       "      <td>1063761</td>\n",
       "      <td>137.391709</td>\n",
       "      <td>10.0</td>\n",
       "      <td>party</td>\n",
       "      <td>This hugged in all the right places! It was a ...</td>\n",
       "      <td>petite</td>\n",
       "      <td>It was a great time to celebrate the (almost) ...</td>\n",
       "      <td>shift</td>\n",
       "      <td>64.0</td>\n",
       "      <td>XS</td>\n",
       "      <td>32.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fit</td>\n",
       "      <td>909926</td>\n",
       "      <td>126335</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>formal affair</td>\n",
       "      <td>I rented this for my company's black tie award...</td>\n",
       "      <td>pear</td>\n",
       "      <td>Dress arrived on time and in perfect condition.</td>\n",
       "      <td>dress</td>\n",
       "      <td>65.0</td>\n",
       "      <td>S</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fit</td>\n",
       "      <td>151944</td>\n",
       "      <td>616682</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>wedding</td>\n",
       "      <td>I have always been petite in my upper body and...</td>\n",
       "      <td>athletic</td>\n",
       "      <td>Was in love with this dress !!!</td>\n",
       "      <td>gown</td>\n",
       "      <td>69.0</td>\n",
       "      <td>M</td>\n",
       "      <td>27.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192539</th>\n",
       "      <td>fit</td>\n",
       "      <td>66386</td>\n",
       "      <td>2252812</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>work</td>\n",
       "      <td>Fit like a glove!</td>\n",
       "      <td>hourglass</td>\n",
       "      <td>LOVE IT!!! First Item Im thinking of buying!</td>\n",
       "      <td>jumpsuit</td>\n",
       "      <td>69.0</td>\n",
       "      <td>S</td>\n",
       "      <td>42.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>dd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192540</th>\n",
       "      <td>fit</td>\n",
       "      <td>118398</td>\n",
       "      <td>682043</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>work</td>\n",
       "      <td>The pattern contrast on this dress is really s...</td>\n",
       "      <td>petite</td>\n",
       "      <td>LOVE it!</td>\n",
       "      <td>dress</td>\n",
       "      <td>61.0</td>\n",
       "      <td>XS</td>\n",
       "      <td>29.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192541</th>\n",
       "      <td>fit</td>\n",
       "      <td>47002</td>\n",
       "      <td>683251</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>everyday</td>\n",
       "      <td>Like the other DVF wraps, the fit on this is f...</td>\n",
       "      <td>straight &amp; narrow</td>\n",
       "      <td>Loud patterning, flattering fit</td>\n",
       "      <td>dress</td>\n",
       "      <td>68.0</td>\n",
       "      <td>S</td>\n",
       "      <td>31.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192542</th>\n",
       "      <td>fit</td>\n",
       "      <td>961120</td>\n",
       "      <td>126335</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>wedding</td>\n",
       "      <td>This dress was PERFECTION.  it looked incredib...</td>\n",
       "      <td>pear</td>\n",
       "      <td>loved this dress it was comfortable and photog...</td>\n",
       "      <td>dress</td>\n",
       "      <td>66.0</td>\n",
       "      <td>L</td>\n",
       "      <td>31.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192543</th>\n",
       "      <td>fit</td>\n",
       "      <td>123612</td>\n",
       "      <td>127865</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>wedding</td>\n",
       "      <td>This dress was wonderful! I had originally pla...</td>\n",
       "      <td>athletic</td>\n",
       "      <td>I wore this to a beautiful black tie optional ...</td>\n",
       "      <td>gown</td>\n",
       "      <td>66.0</td>\n",
       "      <td>L</td>\n",
       "      <td>30.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192544 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fit  user_id  item_id      weight  rating     rented for  \\\n",
       "0       fit   420272  2260466  137.000000    10.0       vacation   \n",
       "1       fit   273551   153475  132.000000    10.0          other   \n",
       "2       fit   360448  1063761  137.391709    10.0          party   \n",
       "3       fit   909926   126335  135.000000     8.0  formal affair   \n",
       "4       fit   151944   616682  145.000000    10.0        wedding   \n",
       "...     ...      ...      ...         ...     ...            ...   \n",
       "192539  fit    66386  2252812  140.000000    10.0           work   \n",
       "192540  fit   118398   682043  100.000000    10.0           work   \n",
       "192541  fit    47002   683251  135.000000     6.0       everyday   \n",
       "192542  fit   961120   126335  165.000000    10.0        wedding   \n",
       "192543  fit   123612   127865  155.000000    10.0        wedding   \n",
       "\n",
       "                                              review_text          body type  \\\n",
       "0       An adorable romper! Belt and zipper were a lit...          hourglass   \n",
       "1       I rented this dress for a photo shoot. The the...  straight & narrow   \n",
       "2       This hugged in all the right places! It was a ...             petite   \n",
       "3       I rented this for my company's black tie award...               pear   \n",
       "4       I have always been petite in my upper body and...           athletic   \n",
       "...                                                   ...                ...   \n",
       "192539                                  Fit like a glove!          hourglass   \n",
       "192540  The pattern contrast on this dress is really s...             petite   \n",
       "192541  Like the other DVF wraps, the fit on this is f...  straight & narrow   \n",
       "192542  This dress was PERFECTION.  it looked incredib...               pear   \n",
       "192543  This dress was wonderful! I had originally pla...           athletic   \n",
       "\n",
       "                                           review_summary  category  height  \\\n",
       "0                                    So many compliments!    romper    68.0   \n",
       "1                                 I felt so glamourous!!!      gown    66.0   \n",
       "2       It was a great time to celebrate the (almost) ...     shift    64.0   \n",
       "3        Dress arrived on time and in perfect condition.      dress    65.0   \n",
       "4                         Was in love with this dress !!!      gown    69.0   \n",
       "...                                                   ...       ...     ...   \n",
       "192539       LOVE IT!!! First Item Im thinking of buying!  jumpsuit    69.0   \n",
       "192540                                           LOVE it!     dress    61.0   \n",
       "192541                    Loud patterning, flattering fit     dress    68.0   \n",
       "192542  loved this dress it was comfortable and photog...     dress    66.0   \n",
       "192543  I wore this to a beautiful black tie optional ...      gown    66.0   \n",
       "\n",
       "       size   age  bust_size bust_type  \n",
       "0         M  28.0       34.0         d  \n",
       "1         M  36.0       34.0         b  \n",
       "2        XS  32.0       34.0         c  \n",
       "3         S  34.0       34.0         c  \n",
       "4         M  27.0       34.0         b  \n",
       "...     ...   ...        ...       ...  \n",
       "192539    S  42.0       34.0        dd  \n",
       "192540   XS  29.0       32.0         c  \n",
       "192541    S  31.0       36.0         a  \n",
       "192542    L  31.0       36.0         c  \n",
       "192543    L  30.0       36.0         b  \n",
       "\n",
       "[192544 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/jayasurya17/cmpe-256-term-project/master/clothing_data_processed.csv\"\n",
    "clothing_data_processed = pd.read_csv(url)\n",
    "clothing_data_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "DTGXt-oefzLo",
    "outputId": "2f232144-5a96-4757-df67-6a3e5a3aefc9"
   },
   "outputs": [],
   "source": [
    "#preprocessed training dataset\n",
    "url1 = \"https://raw.githubusercontent.com/jayasurya17/cmpe-256-term-project/master/train.csv\"\n",
    "train_data = pd.read_csv(url1)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657
    },
    "id": "ilOKJZD2gmC6",
    "outputId": "d303b926-e242-4924-bb2d-51cbeaff140e"
   },
   "outputs": [],
   "source": [
    "#preprocessed test dataset\n",
    "url2 = \"https://raw.githubusercontent.com/jayasurya17/cmpe-256-term-project/master/test.csv\"\n",
    "test_data = pd.read_csv(url2)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G1_un9wEXlEr"
   },
   "outputs": [],
   "source": [
    "#for the train data - list out all users to avoid repetation and place an index to each user.\n",
    "user_ids_train = train_data[\"user_id\"].unique().tolist()\n",
    "\n",
    "#index all the unique users\n",
    "user2user_encoded_train = {x: i for i, x in enumerate(user_ids_train)}\n",
    "#print(user2user_encoded_train)\n",
    "\n",
    "userencoded2user_train = {i: x for i, x in enumerate(user_ids_train)}\n",
    "#print(userencoded2user_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SGyOwEIfxXN9"
   },
   "outputs": [],
   "source": [
    "#for the test data - list out all users to avoid repetation and place an index to each user.\n",
    "user_ids_test = test_data[\"user_id\"].unique().tolist()\n",
    "\n",
    "#index all the unique users\n",
    "user2user_encoded_test = {x: i for i, x in enumerate(user_ids_test)}\n",
    "#print(user2user_encoded_test)\n",
    "\n",
    "userencoded2user_test = {i: x for i, x in enumerate(user_ids_test)}\n",
    "#print(userencoded2user_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-uc0vdfOXzb0"
   },
   "outputs": [],
   "source": [
    "#for the train data - list out all items, to avoid repetation and place an index to each items.\n",
    "item_ids_train = train_data[\"item_id\"].unique().tolist()\n",
    "\n",
    "item2item_encoded_train = {x: i for i, x in enumerate(item_ids_train)}\n",
    "#print(item2item_encoded_train)\n",
    "\n",
    "itemencoded2item_train = {i: x for i, x in enumerate(item_ids_train)}\n",
    "#print(itemencoded2item_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hx6YV4Y_yuTi"
   },
   "outputs": [],
   "source": [
    "#for the test data - list out all items, to avoid repetation and place an index to each items.\n",
    "item_ids_test = test_data[\"item_id\"].unique().tolist()\n",
    "\n",
    "item2item_encoded_test = {x: i for i, x in enumerate(item_ids_test)}\n",
    "#print(item2item_encoded_test)\n",
    "\n",
    "itemencoded2item_test= {i: x for i, x in enumerate(item_ids_test)}\n",
    "#print(itemencoded2item_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g3CpLqXg1PVI",
    "outputId": "ad5e2fee-200c-413a-b3cc-47c32cebfd9b"
   },
   "outputs": [],
   "source": [
    "#mapping back to the train_data dataframe\n",
    "train_data[\"userfind\"] = train_data[\"user_id\"].map(user2user_encoded_train)\n",
    "train_data[\"itemfind\"] = train_data[\"item_id\"].map(item2item_encoded_train)\n",
    "print (train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0QRrBOUU1nyy",
    "outputId": "0dcfcb8b-9ed9-4f28-d337-2e48a614b211"
   },
   "outputs": [],
   "source": [
    "#mapping back to the test_data dataframe\n",
    "test_data[\"userfind\"] = test_data[\"user_id\"].map(user2user_encoded_test)\n",
    "test_data[\"itemfind\"] = test_data[\"item_id\"].map(item2item_encoded_test)\n",
    "print (test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZTZy_Wot4QVO",
    "outputId": "d9c0c977-efa9-464f-d26b-3ccacee9f330"
   },
   "outputs": [],
   "source": [
    "#preparing train set\n",
    "num_users_train = len(user2user_encoded_train)\n",
    "num_items_train = len(itemencoded2item_train)\n",
    "\n",
    "train_data[\"rating\"] = train_data[\"rating\"].values.astype(np.float32)\n",
    "\n",
    "# min and max ratings will be used to normalize the ratings later\n",
    "min_rating = min(train_data[\"rating\"])\n",
    "max_rating = max(train_data[\"rating\"])\n",
    "\n",
    "print(\n",
    "    \"Number of users in train data: {}, Number of items in train data: {}, Min rating: {}, Max rating: {}\".\n",
    "     format(num_users_train, num_items_train, min_rating, max_rating)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "84DDtj_n4-Qu"
   },
   "outputs": [],
   "source": [
    "#Prepare training and validation dataset\n",
    "\n",
    "x = train_data[[\"userfind\", \"itemfind\"]].values\n",
    "\n",
    "# Normalize the targets between 0 and 1. Makes it easy to train.\n",
    "y = train_data[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
    "\n",
    "# Assuming training on 80% of the data and validating on 20%.\n",
    "train_indices = int(0.80 * train_data.shape[0])  #take 80% of the rows as training data\n",
    "\n",
    "x_train, x_val, y_train, y_val = (\n",
    "    x[:train_indices],\n",
    "    x[train_indices:],\n",
    "    y[:train_indices],\n",
    "    y[train_indices:],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8QoSMkIfmKyC"
   },
   "source": [
    "### Neural network based CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2VKq-l6GmNt2"
   },
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import BaselineOnly\n",
    "\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from pathlib import Path\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSSsEZ7Rmk-5"
   },
   "source": [
    "https://towardsdatascience.com/movie-recommender-system-a5dbfdb2585d\n",
    "\n",
    "he_normal> It draws samples from a truncated normal distribution centered on 0 with stddev = sqrt(2 / fan_in) where fan_in is the number of input units in the weight tensor.\n",
    "\n",
    "EMBEDDING_SIZE>  Embedding is the concept of mapping from discrete objects such as words to vectors and real numbers. \n",
    "Keras offers an Embedding layer that can be used for neural networks on text data. It requires that the input data be integer encoded, so that each word is represented by a unique integer. This data preparation step can be performed using the Tokenizer API also provided with Keras.\n",
    "There are a few different embedding vector sizes, including 50, 100, 200 and 300 dimensions. You can download this collection of embeddings and we can seed the Keras Embedding layer with weights from the pre-trained embedding for the words in your training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OqfQD0MNmmGq"
   },
   "outputs": [],
   "source": [
    "#defined the embedding layer size\n",
    "EMBEDDING_SIZE = 100\n",
    "\n",
    "\n",
    "class RecommenderNet(keras.Model):\n",
    "    def __init__(self, num_users, num_items, embedding_size, **kwargs):\n",
    "        super(RecommenderNet, self).__init__(**kwargs)\n",
    "        \n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_size = embedding_size\n",
    "        #doing embedding on user\n",
    "        self.user_embedding = layers.Embedding(\n",
    "            num_users,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.user_bias = layers.Embedding(num_users, 1)\n",
    "        \n",
    "        \n",
    "        #doing embedding on item\n",
    "        self.items_embedding = layers.Embedding(\n",
    "            num_items,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.items_bias = layers.Embedding(num_items, 1)\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        #preparing user vectors and item vectors\n",
    "        user_vector = self.user_embedding(inputs[:, 0]) \n",
    "        user_bias = self.user_bias(inputs[:, 0])  \n",
    "        items_vector = self.items_embedding(inputs[:, 1])\n",
    "        items_bias = self.items_bias(inputs[:, 1])  \n",
    "        \n",
    "        #dot product of vectors\n",
    "        dot_user_items = tf.tensordot(user_vector, items_vector, 2)\n",
    "        \n",
    "        x = dot_user_items + user_bias + items_bias\n",
    "        # normalized rating\n",
    "        return tf.nn.sigmoid(x)\n",
    "\n",
    "model = RecommenderNet(num_users_train, num_items_train, EMBEDDING_SIZE)\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(lr=0.001)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xs1L8JxvmqTF",
    "outputId": "1ef87ea8-731a-452a-f9e9-483e15235246"
   },
   "outputs": [],
   "source": [
    "#calculating the loss\n",
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=100,\n",
    "    epochs=5,\n",
    "    verbose=1,\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "ffJ7pE5YmuQv",
    "outputId": "5c6e8311-334e-4bc6-9cb9-7eec1c1e48d6"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QeRLnG2Vmwre"
   },
   "outputs": [],
   "source": [
    "#evaluation by MSE, MAE\n",
    "model = RecommenderNet(num_users_train, num_items_train, EMBEDDING_SIZE)\n",
    "model.compile(\n",
    "    keras.optimizers.Adam(lr=0.001), loss=\"mean_squared_error\",\n",
    "    metrics=[\"mean_absolute_error\", \"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rfk3DSywm68x",
    "outputId": "f3205c2c-025b-42f7-bf6d-69c8ca1036db"
   },
   "outputs": [],
   "source": [
    "#calculating the errors\n",
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=100,\n",
    "    epochs=5,\n",
    "    verbose=1,\n",
    "    validation_data=(x_val, y_val),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "Mow0hUoPm-q7",
    "outputId": "7d9b1c61-eedd-4e84-fc96-3a38932af161"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kjGwy058jwx"
   },
   "source": [
    " # Selected an user from test data and recommended items "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z8fjlP4BnCMA",
    "outputId": "f31f7f76-7b57-440a-8de6-526071b4b9a8"
   },
   "outputs": [],
   "source": [
    "# what a user has already reviewed\n",
    "\n",
    "#user_selected = test_data[\"user_id\"] == '492205'\n",
    "user_selected = test_data.user_id.sample(1).iloc[0]  \n",
    "\n",
    "items_reviewed_by_user = test_data[test_data.user_id == user_selected]\n",
    "print(items_reviewed_by_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zijd0NP9csFI"
   },
   "outputs": [],
   "source": [
    "#what a user has not already reviewed\n",
    "items__not_reviewed = test_data[~test_data[\"item_id\"].isin(items_reviewed_by_user.item_id.values)][\"item_id\"]\n",
    "\n",
    "items__not_reviewed = list(set(items__not_reviewed).intersection(set(item2item_encoded_test.keys())))\n",
    "\n",
    "items__not_reviewed = [[item2item_encoded_test.get(x)] for x in items__not_reviewed]\n",
    "\n",
    "user_encoder = user2user_encoded_test.get(user_selected)\n",
    "\n",
    "user_item_array = np.hstack(([[user_encoder]] * len(items__not_reviewed), items__not_reviewed))  #user_item_array consists of selected_user in userfind and itemfind\n",
    "\n",
    "rate = model.predict(user_item_array)\n",
    "ratings = model.predict(user_item_array).flatten()\n",
    "\n",
    "\n",
    "#For any iterable in python [-10:] denotes the indexing of last 10 items of that iterable.\n",
    "#[::-1] denotes same list in reverse order\n",
    "#returns top 10 max ratings' indices\n",
    "top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
    "recommended_item_ids = [\n",
    "    itemencoded2item_test.get(items__not_reviewed[x][0]) for x in top_ratings_indices\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i8TJaAFZ-Xdf",
    "outputId": "406d10b7-2ac2-4fbe-df48-f6d983a54a52"
   },
   "outputs": [],
   "source": [
    "print(user_item_array)\n",
    "print(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5HWnwsWu-dHs",
    "outputId": "9d60ed64-722e-46d9-dc49-6b94b212b47a"
   },
   "outputs": [],
   "source": [
    "print (top_ratings_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FhvGd2N8-hBK",
    "outputId": "ad653c65-bceb-4b9d-8819-4efc964d26d3"
   },
   "outputs": [],
   "source": [
    "#recommended items \n",
    "print(\"Showing recommendations for user: {}\".format(user_selected))\n",
    "\n",
    "print(\"Top 10 items recommendations\")\n",
    "\n",
    "recommended_items = test_data[test_data[\"item_id\"].isin(recommended_item_ids)]\n",
    "recommended_items = recommended_items.drop_duplicates(subset = [\"item_id\"])\n",
    "\n",
    "for row in recommended_items.itertuples():\n",
    "    print(row.item_id)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Neural network based cf.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
